{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Model training **\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aPAmRk8eyAp-"
      }
    },
    {
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import pickle\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"ford.csv\"  # Update this path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display dataset information\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "\n",
        "# Handle missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoders = {}\n",
        "categorical_cols = ['model', 'transmission', 'fuelType']\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le  # Save encoder for future use\n",
        "\n",
        "# Save the fitted label encoders\n",
        "with open('label_encoders.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoders, f)\n",
        "\n",
        "# Save the scaler after fitting\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = [\"year\", \"mileage\", \"tax\", \"mpg\", \"engineSize\"]\n",
        "X_numerical = df[numerical_cols].values\n",
        "scaler.fit(X_numerical)\n",
        "with open('scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "# Select features and target variable\n",
        "FEATURES = [\"year\", \"mileage\", \"tax\", \"mpg\", \"engineSize\", \"model\", \"transmission\", \"fuelType\"]\n",
        "TARGET = \"price\"\n",
        "X = df[FEATURES].values\n",
        "y = df[TARGET].values\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = [\"year\", \"mileage\", \"tax\", \"mpg\", \"engineSize\"]  # Only numerical columns to scale\n",
        "X[:, :5] = scaler.fit_transform(X[:, :5])  # Scale numerical columns only\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model architecture\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Regression output\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Save trained model\n",
        "model.save(\"car_price_model.h5\")\n",
        "print(\"Model saved as car_price_model.h5\")\n",
        "\n",
        "# Load trained model\n",
        "MODEL_PATH = \"car_price_model.h5\"\n",
        "try:\n",
        "    # Explicitly specify 'mse' as a custom object\n",
        "    model = keras.models.load_model(MODEL_PATH, custom_objects={'mse': tf.keras.losses.MeanSquaredError()})\n",
        "    print(f\"Model loaded successfully from {MODEL_PATH}\")\n",
        "except OSError:\n",
        "    print(f\"Error: Model file '{MODEL_PATH}' not found. Ensure the model is trained and saved correctly.\")\n",
        "    exit()\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQK6nfKDZdPn",
        "outputId": "f6625135-3d6f-4f13-d9f5-9dedc8ced3ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     model  year  price transmission  mileage fuelType  tax   mpg  engineSize\n",
            "0   Fiesta  2017  12000    Automatic    15944   Petrol  150  57.7         1.0\n",
            "1    Focus  2018  14000       Manual     9083   Petrol  150  57.7         1.0\n",
            "2    Focus  2017  13000       Manual    12456   Petrol  150  57.7         1.0\n",
            "3   Fiesta  2019  17500       Manual    10460   Petrol  145  40.3         1.5\n",
            "4   Fiesta  2019  16500    Automatic     1482   Petrol  145  48.7         1.0\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17966 entries, 0 to 17965\n",
            "Data columns (total 9 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   model         17966 non-null  object \n",
            " 1   year          17966 non-null  int64  \n",
            " 2   price         17966 non-null  int64  \n",
            " 3   transmission  17966 non-null  object \n",
            " 4   mileage       17966 non-null  int64  \n",
            " 5   fuelType      17966 non-null  object \n",
            " 6   tax           17966 non-null  int64  \n",
            " 7   mpg           17966 non-null  float64\n",
            " 8   engineSize    17966 non-null  float64\n",
            "dtypes: float64(2), int64(4), object(3)\n",
            "memory usage: 1.2+ MB\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 164864112.0000 - mae: 11910.6729 - val_loss: 62394908.0000 - val_mae: 6908.0225\n",
            "Epoch 2/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 38350072.0000 - mae: 4915.6025 - val_loss: 18702740.0000 - val_mae: 3060.4185\n",
            "Epoch 3/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 18816598.0000 - mae: 3032.8672 - val_loss: 16455165.0000 - val_mae: 2864.1089\n",
            "Epoch 4/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16463259.0000 - mae: 2857.9246 - val_loss: 14429498.0000 - val_mae: 2677.7649\n",
            "Epoch 5/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 13805301.0000 - mae: 2623.2654 - val_loss: 12622260.0000 - val_mae: 2512.3640\n",
            "Epoch 6/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12804717.0000 - mae: 2489.5679 - val_loss: 11055609.0000 - val_mae: 2362.1880\n",
            "Epoch 7/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 11692061.0000 - mae: 2384.0752 - val_loss: 9788828.0000 - val_mae: 2231.7688\n",
            "Epoch 8/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 10304780.0000 - mae: 2254.6770 - val_loss: 8843564.0000 - val_mae: 2123.6917\n",
            "Epoch 9/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 9572152.0000 - mae: 2133.2583 - val_loss: 8192959.0000 - val_mae: 2039.1814\n",
            "Epoch 10/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8460707.0000 - mae: 2030.8285 - val_loss: 7655163.0000 - val_mae: 1977.5431\n",
            "Epoch 11/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7770420.5000 - mae: 1965.3967 - val_loss: 7228955.5000 - val_mae: 1925.0178\n",
            "Epoch 12/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7599256.0000 - mae: 1899.4423 - val_loss: 6873911.0000 - val_mae: 1872.2971\n",
            "Epoch 13/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8165065.0000 - mae: 1869.6862 - val_loss: 6582092.5000 - val_mae: 1835.8679\n",
            "Epoch 14/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6816391.0000 - mae: 1813.3542 - val_loss: 6323007.5000 - val_mae: 1813.2345\n",
            "Epoch 15/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6237940.0000 - mae: 1775.0753 - val_loss: 6165060.0000 - val_mae: 1804.9529\n",
            "Epoch 16/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7612936.0000 - mae: 1773.7473 - val_loss: 5849173.5000 - val_mae: 1741.5054\n",
            "Epoch 17/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 5911766.5000 - mae: 1709.6111 - val_loss: 5684261.5000 - val_mae: 1723.6328\n",
            "Epoch 18/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5884344.5000 - mae: 1706.0450 - val_loss: 5499981.5000 - val_mae: 1687.6204\n",
            "Epoch 19/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5774820.5000 - mae: 1657.6224 - val_loss: 5358137.5000 - val_mae: 1676.0066\n",
            "Epoch 20/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5405566.5000 - mae: 1637.5371 - val_loss: 5221004.0000 - val_mae: 1650.2153\n",
            "Epoch 21/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5079073.5000 - mae: 1597.8702 - val_loss: 5119093.0000 - val_mae: 1631.1622\n",
            "Epoch 22/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5242430.5000 - mae: 1599.0001 - val_loss: 5034951.5000 - val_mae: 1621.8475\n",
            "Epoch 23/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5413330.5000 - mae: 1573.1321 - val_loss: 4947192.0000 - val_mae: 1602.9988\n",
            "Epoch 24/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5346579.0000 - mae: 1561.4993 - val_loss: 4876682.0000 - val_mae: 1590.0242\n",
            "Epoch 25/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6307129.0000 - mae: 1573.0540 - val_loss: 4805370.0000 - val_mae: 1579.6884\n",
            "Epoch 26/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4734025.5000 - mae: 1534.1931 - val_loss: 4788550.5000 - val_mae: 1587.9415\n",
            "Epoch 27/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4761392.0000 - mae: 1518.2184 - val_loss: 4718691.0000 - val_mae: 1565.5758\n",
            "Epoch 28/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5061195.5000 - mae: 1542.7472 - val_loss: 4682377.0000 - val_mae: 1559.2456\n",
            "Epoch 29/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5228900.0000 - mae: 1532.2659 - val_loss: 4661756.5000 - val_mae: 1556.7194\n",
            "Epoch 30/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4846504.0000 - mae: 1526.8152 - val_loss: 4629941.5000 - val_mae: 1549.3651\n",
            "Epoch 31/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5205961.5000 - mae: 1517.3002 - val_loss: 4597517.0000 - val_mae: 1548.5320\n",
            "Epoch 32/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4615698.5000 - mae: 1489.4125 - val_loss: 4586709.0000 - val_mae: 1546.5168\n",
            "Epoch 33/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4833031.0000 - mae: 1502.0488 - val_loss: 4553968.0000 - val_mae: 1536.7145\n",
            "Epoch 34/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4405269.5000 - mae: 1473.7100 - val_loss: 4554215.0000 - val_mae: 1532.2648\n",
            "Epoch 35/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4332444.0000 - mae: 1474.3423 - val_loss: 4532018.0000 - val_mae: 1532.7045\n",
            "Epoch 36/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4928330.0000 - mae: 1491.4165 - val_loss: 4551072.5000 - val_mae: 1539.4014\n",
            "Epoch 37/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5554998.5000 - mae: 1506.2456 - val_loss: 4510190.0000 - val_mae: 1528.8586\n",
            "Epoch 38/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4319214.5000 - mae: 1490.8755 - val_loss: 4487317.0000 - val_mae: 1526.6064\n",
            "Epoch 39/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4869211.0000 - mae: 1501.8480 - val_loss: 4487175.5000 - val_mae: 1523.0291\n",
            "Epoch 40/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4401764.0000 - mae: 1472.6323 - val_loss: 4460139.5000 - val_mae: 1518.7371\n",
            "Epoch 41/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4821975.0000 - mae: 1491.2500 - val_loss: 4451274.5000 - val_mae: 1518.0337\n",
            "Epoch 42/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4376272.0000 - mae: 1468.9064 - val_loss: 4443472.0000 - val_mae: 1515.7479\n",
            "Epoch 43/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4507285.0000 - mae: 1486.1287 - val_loss: 4432198.5000 - val_mae: 1512.9692\n",
            "Epoch 44/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4344655.0000 - mae: 1471.6396 - val_loss: 4420391.0000 - val_mae: 1514.2396\n",
            "Epoch 45/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4254191.0000 - mae: 1474.3268 - val_loss: 4407666.5000 - val_mae: 1510.8975\n",
            "Epoch 46/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4253910.0000 - mae: 1455.7551 - val_loss: 4401034.5000 - val_mae: 1507.5641\n",
            "Epoch 47/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4462839.5000 - mae: 1473.7216 - val_loss: 4392645.5000 - val_mae: 1507.3353\n",
            "Epoch 48/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4816231.0000 - mae: 1460.9814 - val_loss: 4346183.5000 - val_mae: 1499.8776\n",
            "Epoch 49/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4356206.5000 - mae: 1434.4104 - val_loss: 4344896.5000 - val_mae: 1499.5560\n",
            "Epoch 50/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4545911.0000 - mae: 1460.5334 - val_loss: 4371579.5000 - val_mae: 1506.9988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as car_price_model.h5\n",
            "Model loaded successfully from car_price_model.h5\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "except ModuleNotFoundError:\n",
        "    print(\"Error: TensorFlow is not installed. Please install it using 'pip install tensorflow'.\")\n",
        "    exit()\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import json\n",
        "\n",
        "# API URL\n",
        "API_URL = \"https://databases-peer-16.onrender.com/cars\"\n",
        "\n",
        "try:\n",
        "    with open('label_encoders.pkl', 'rb') as f:\n",
        "        label_encoders = pickle.load(f)\n",
        "    with open('scaler.pkl', 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "    print(\"Loaded preprocessing transformers successfully\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Preprocessing transformers not found. Please run the training script first.\")\n",
        "    exit()\n",
        "\n",
        "# Fetch latest car data\n",
        "def fetch_latest_car():\n",
        "    response = requests.get(API_URL)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        print(\"Failed to fetch data\")\n",
        "        return None\n",
        "\n",
        "# Load trained model\n",
        "MODEL_PATH = \"car_price_model.h5\"\n",
        "\n",
        "# Check if model file exists\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    print(f\"Error: Model file '{MODEL_PATH}' not found. Please make sure it is in the correct directory.\")\n",
        "    exit()\n",
        "\n",
        "try:\n",
        "    # Explicitly specify 'mse' as a custom object\n",
        "    model = keras.models.load_model(MODEL_PATH, custom_objects={'mse': tf.keras.losses.MeanSquaredError()})\n",
        "    print(\"Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    exit()\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6wlIrsmct1N",
        "outputId": "1524b612-f7b3-48e3-d868-9a7ebb453da5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded preprocessing transformers successfully\n",
            "Model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained model\n",
        "MODEL_PATH = \"car_price_model.h5\"\n",
        "\n",
        "# Check if model file exists\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    print(f\"Error: Model file '{MODEL_PATH}' not found. Please make sure it is in the correct directory.\")\n",
        "    exit()\n",
        "\n",
        "try:\n",
        "    # Load model\n",
        "    model = keras.models.load_model(MODEL_PATH, custom_objects={'mse': tf.keras.losses.MeanSquaredError()})\n",
        "    print(\"Model loaded successfully.\")\n",
        "\n",
        "    # Recompile model to avoid metrics warning\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    print(\"Model recompiled successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    exit()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpzVSKYz2doh",
        "outputId": "279fee9c-a263-45c6-87c0-9b63d8243253"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n",
            "Model recompiled successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Data fetching***"
      ],
      "metadata": {
        "id": "M1l5irp3y9tV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_URL = \"https://databases-peer-16.onrender.com/cars/?limit=1\"\n",
        "response = requests.get(API_URL)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    print(\"Fetched Data:\", data)\n",
        "else:\n",
        "    print(f\"Failed to fetch data. Status code: {response.status_code}, Response: {response.text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2rVMrmSlBSH",
        "outputId": "5e54bb61-e4ac-4536-9b8d-c7a74c63bb90"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched Data: [{'model': ' Fiesta', 'year': 2017, 'price': 12000.0, 'mileage': 15944, 'tax': 150, 'mpg': 57.7, 'enginesize': 1.0, 'carid': 2, 'transmissionid': 2, 'fueltypeid': 2}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Prediction making***"
      ],
      "metadata": {
        "id": "CVv2O3q9zMgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"***Prediction making***\"\"\"\n",
        "\n",
        "import requests\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import pickle\n",
        "\n",
        "# API URL to fetch the latest car data\n",
        "API_URL = \"https://databases-peer-16.onrender.com/cars/?limit=1\"\n",
        "\n",
        "# Load the fitted label encoders and scaler\n",
        "try:\n",
        "    with open('label_encoders.pkl', 'rb') as f:\n",
        "        label_encoders = pickle.load(f)\n",
        "    with open('scaler.pkl', 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "    print(\"Loaded preprocessing transformers successfully\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Preprocessing transformers not found. Please run the training script first.\")\n",
        "    exit()\n",
        "\n",
        "# Fetch latest car data\n",
        "def fetch_latest_car():\n",
        "    response = requests.get(API_URL)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        if data and len(data) > 0:\n",
        "            print(\"Raw API response:\", data[0])  # Debug print\n",
        "            return data[0]\n",
        "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
        "    return None\n",
        "\n",
        "# Feature columns (ensure the order matches training data)\n",
        "NUMERICAL_FEATURES = [\"year\", \"mileage\", \"tax\", \"mpg\", \"engineSize\"]\n",
        "CATEGORICAL_FEATURES = {\n",
        "    'model': 'model',\n",
        "    'transmission': 'transmissionid',\n",
        "    'fuelType': 'fueltypeid'\n",
        "}\n",
        "\n",
        "def safe_transform(encoder, value, feature_name):\n",
        "    try:\n",
        "        # Get all classes that the encoder knows about\n",
        "        known_classes = encoder.classes_\n",
        "\n",
        "        # If the value isn't in known classes, use the most common class\n",
        "        if value not in known_classes:\n",
        "            print(f\"Warning: Unknown {feature_name} value '{value}'. Using fallback value '{known_classes[0]}'\")\n",
        "            value = known_classes[0]\n",
        "\n",
        "        return encoder.transform([value])[0]\n",
        "    except Exception as e:\n",
        "        print(f\"Error transforming {feature_name}: {e}\")\n",
        "        # Return the first encoded value as fallback\n",
        "        return 0\n",
        "\n",
        "# Preprocess the data (categorical encoding and numerical scaling)\n",
        "def preprocess_data(car_data):\n",
        "    if not car_data:\n",
        "        print(\"No car data provided\")\n",
        "        return None\n",
        "\n",
        "    # Debug print\n",
        "    print(\"\\nProcessing car data:\")\n",
        "    print(\"Numerical features expected:\", NUMERICAL_FEATURES)\n",
        "    print(\"Categorical features mapping:\", CATEGORICAL_FEATURES)\n",
        "    print(\"Available data fields:\", car_data.keys())\n",
        "\n",
        "    # Handle categorical features\n",
        "    encoded_data = []\n",
        "    for original_col, api_col in CATEGORICAL_FEATURES.items():\n",
        "        try:\n",
        "            value = car_data.get(api_col)\n",
        "            if value is None:\n",
        "                print(f\"Warning: Missing {api_col} in API response\")\n",
        "                value = label_encoders[original_col].classes_[0]  # Use first known class as fallback\n",
        "\n",
        "            encoded_value = safe_transform(label_encoders[original_col], value, api_col)\n",
        "            encoded_data.append(encoded_value)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing categorical feature {api_col}: {e}\")\n",
        "            encoded_data.append(0)  # Fallback value\n",
        "\n",
        "    # Handle numerical features\n",
        "    numerical_data = []\n",
        "    for feature in NUMERICAL_FEATURES:\n",
        "        try:\n",
        "            # Try both original case and lowercase\n",
        "            value = car_data.get(feature) or car_data.get(feature.lower())\n",
        "            if value is None:\n",
        "                print(f\"Warning: Missing numerical feature {feature}\")\n",
        "                value = 0  # Fallback value\n",
        "            numerical_data.append(float(value))\n",
        "        except (KeyError, ValueError) as e:\n",
        "            print(f\"Error processing numerical feature {feature}: {e}\")\n",
        "            numerical_data.append(0)  # Fallback value\n",
        "\n",
        "    try:\n",
        "        # Scale numerical features\n",
        "        normalized_data = scaler.transform([numerical_data])\n",
        "\n",
        "        # Combine numerical and categorical features\n",
        "        final_data = np.concatenate([normalized_data[0], encoded_data])\n",
        "        return final_data.reshape(1, -1)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in final data preparation: {e}\")\n",
        "        return None\n",
        "\n",
        "# Predict car price\n",
        "def predict_price():\n",
        "    latest_car = fetch_latest_car()\n",
        "    if latest_car:\n",
        "        try:\n",
        "            input_data = preprocess_data(latest_car)\n",
        "            if input_data is not None:\n",
        "                predicted_price = model.predict(input_data)[0][0]\n",
        "                print(f\"\\nPredicted Price: ${predicted_price:.2f}\")\n",
        "            else:\n",
        "                print(\"Failed to preprocess data\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error during prediction: {e}\")\n",
        "            import traceback\n",
        "            print(\"Full error:\", traceback.format_exc())\n",
        "    else:\n",
        "        print(\"No data available for prediction.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    predict_price()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_-SXXDYBKb8",
        "outputId": "03811559-49ed-45b6-c33d-56fb5446809c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded preprocessing transformers successfully\n",
            "Raw API response: {'model': ' Fiesta', 'year': 2017, 'price': 12000.0, 'mileage': 15944, 'tax': 150, 'mpg': 57.7, 'enginesize': 1.0, 'carid': 2, 'transmissionid': 2, 'fueltypeid': 2}\n",
            "\n",
            "Processing car data:\n",
            "Numerical features expected: ['year', 'mileage', 'tax', 'mpg', 'engineSize']\n",
            "Categorical features mapping: {'model': 'model', 'transmission': 'transmissionid', 'fuelType': 'fueltypeid'}\n",
            "Available data fields: dict_keys(['model', 'year', 'price', 'mileage', 'tax', 'mpg', 'enginesize', 'carid', 'transmissionid', 'fueltypeid'])\n",
            "Warning: Unknown transmissionid value '2'. Using fallback value 'Automatic'\n",
            "Warning: Unknown fueltypeid value '2'. Using fallback value 'Diesel'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
            "\n",
            "Predicted Price: $11467.76\n"
          ]
        }
      ]
    }
  ]
}